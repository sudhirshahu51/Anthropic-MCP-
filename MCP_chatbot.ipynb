{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOjUrtJ1HcRvRDq9Ck9nj9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhirshahu51/Anthropic-MCP-/blob/main/MCP_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owQ-UxLtsXzb",
        "outputId": "4ff370c9-f27e-4ca1-badb-44e4c5e2749f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install arxiv anthropic dotenv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import anthropic"
      ],
      "metadata": {
        "id": "dcURMbhgtAbk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_DIR = \"papers\""
      ],
      "metadata": {
        "id": "dTQlkf0EtBKm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    Search for papers on arXiv based on a topic and store their information.\n",
        "\n",
        "    Args:\n",
        "        topic: The topic to search for\n",
        "        max_results: Maximum number of results to retrieve (default: 5)\n",
        "\n",
        "    Returns:\n",
        "        List of paper IDs found in the search\n",
        "    \"\"\"\n",
        "\n",
        "    # Use arxiv to find the papers\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the most relevant articles matching the queried topic\n",
        "    search = arxiv.Search(\n",
        "        query = topic,\n",
        "        max_results = max_results,\n",
        "        sort_by = arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    papers = client.results(search)\n",
        "\n",
        "    # Create directory for this topic\n",
        "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(path, \"papers_info.json\")\n",
        "\n",
        "    # Try to load existing papers info\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            papers_info = json.load(json_file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        papers_info = {}\n",
        "\n",
        "    # Process each paper and add to papers_info\n",
        "    paper_ids = []\n",
        "    for paper in papers:\n",
        "        paper_ids.append(paper.get_short_id())\n",
        "        paper_info = {\n",
        "            'title': paper.title,\n",
        "            'authors': [author.name for author in paper.authors],\n",
        "            'summary': paper.summary,\n",
        "            'pdf_url': paper.pdf_url,\n",
        "            'published': str(paper.published.date())\n",
        "        }\n",
        "        papers_info[paper.get_short_id()] = paper_info\n",
        "\n",
        "    # Save updated papers_info to json file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(papers_info, json_file, indent=2)\n",
        "\n",
        "    print(f\"Results are saved in: {file_path}\")\n",
        "\n",
        "    return paper_ids"
      ],
      "metadata": {
        "id": "HI6jxb67tqwc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_papers(\"computers\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdHvHRGKvuGK",
        "outputId": "3aad2395-ba42-4bc6-95bc-15e58935a523"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results are saved in: papers/computers/papers_info.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1310.7911v2',\n",
              " 'math/9711204v1',\n",
              " '2208.00733v1',\n",
              " '2504.07020v1',\n",
              " '2403.03925v1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second tool looks for information about a specific paper across all topic directories inside the papers directory."
      ],
      "metadata": {
        "id": "-NOGcHdIzALr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info(paper_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific paper across all topic directories.\n",
        "\n",
        "    Args:\n",
        "        paper_id: The ID of the paper to look for\n",
        "\n",
        "    Returns:\n",
        "        JSON string with paper information if found, error message if not found\n",
        "    \"\"\"\n",
        "\n",
        "    for item in os.listdir(PAPER_DIR):\n",
        "        item_path = os.path.join(PAPER_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        papers_info = json.load(json_file)\n",
        "                        if paper_id in papers_info:\n",
        "                            return json.dumps(papers_info[paper_id], indent=2)\n",
        "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    return f\"There's no saved information related to paper {paper_id}.\""
      ],
      "metadata": {
        "id": "QllTr2JByneS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_info('1310.7911v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "BJRHAXMtzG1G",
        "outputId": "88e74f63-d2d8-407f-9d13-923d1876056a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tool Schema"
      ],
      "metadata": {
        "id": "3hjU9ABOzRzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the schema of each tool which you will provide to the LLM."
      ],
      "metadata": {
        "id": "qpUIcDFUzaFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"name\": \"search_papers\",\n",
        "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"topic\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The topic to search for\"\n",
        "                },\n",
        "                \"max_results\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"Maximum number of results to retrieve\",\n",
        "                    \"default\": 5\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"topic\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"extract_info\",\n",
        "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"paper_id\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The ID of the paper to look for\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"paper_id\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "SMrcsEIhzLTV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Tool Mapping"
      ],
      "metadata": {
        "id": "IYdEIs-fzlbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code handles tool mapping and execution."
      ],
      "metadata": {
        "id": "8bgh6mz1zwri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_tool_function = {\n",
        "    \"search_papers\": search_papers,\n",
        "    \"extract_info\": extract_info\n",
        "}\n",
        "\n",
        "def execute_tool(tool_name, tool_args):\n",
        "\n",
        "    result = mapping_tool_function[tool_name](**tool_args)\n",
        "\n",
        "    if result is None:\n",
        "        result = \"The operation completed but didn't return any results.\"\n",
        "\n",
        "    elif isinstance(result, list):\n",
        "        result = ', '.join(result)\n",
        "\n",
        "    elif isinstance(result, dict):\n",
        "        # Convert dictionaries to formatted JSON strings\n",
        "        result = json.dumps(result, indent=2)\n",
        "\n",
        "    else:\n",
        "        # For any other type, convert using str()\n",
        "        result = str(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "eBGkpm_Wzu_d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot Code"
      ],
      "metadata": {
        "id": "AJq_P3Wj0nn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "key = userdata.get('ANTHROPIC')\n",
        "#os.environ['ANTHROPIC_API_KEY'] = key"
      ],
      "metadata": {
        "id": "aVgkLGds2w2v"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
      ],
      "metadata": {
        "id": "dN_0k-Dv0pzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "client = anthropic.Anthropic(api_key=userdata.get('ANTHROPIC'))\n",
        "\n",
        "#client = anthropic.Anthropic()#api_key='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJhcHAiLCJleHAiOjE3OTk5OTk5OTksInN1YiI6ODQ0Njk4LCJhdWQiOiJXRUIiLCJpYXQiOjE2OTQwNzY4NTF9.OPgWNs_8qm6SshI_4UFb5bCwpXGGAZ6ER61UzIqwyyo')"
      ],
      "metadata": {
        "id": "PtKv5iXs0vhB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query Processing"
      ],
      "metadata": {
        "id": "jwIQmTQ603lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello, Claude\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"claude-3-5-sonnet-latest\",\n",
        ")\n",
        "print(message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OB24Y1r46cD",
        "outputId": "6d3005c3-b40b-44d7-b421-cdad55c9f0ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TextBlock(citations=None, text='Hello! How can I help you today?', type='text')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query(query):\n",
        "\n",
        "    messages = [{'role': 'user', 'content': query}]\n",
        "\n",
        "    response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "    process_query = True\n",
        "    while process_query:\n",
        "        assistant_content = []\n",
        "\n",
        "        for content in response.content:\n",
        "            if content.type == 'text':\n",
        "\n",
        "                print(content.text)\n",
        "                assistant_content.append(content)\n",
        "\n",
        "                if len(response.content) == 1:\n",
        "                    process_query = False\n",
        "\n",
        "            elif content.type == 'tool_use':\n",
        "\n",
        "                assistant_content.append(content)\n",
        "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
        "\n",
        "                tool_id = content.id\n",
        "                tool_args = content.input\n",
        "                tool_name = content.name\n",
        "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
        "\n",
        "                result = execute_tool(tool_name, tool_args)\n",
        "                messages.append({\"role\": \"user\",\n",
        "                                  \"content\": [\n",
        "                                      {\n",
        "                                          \"type\": \"tool_result\",\n",
        "                                          \"tool_use_id\": tool_id,\n",
        "                                          \"content\": result\n",
        "                                      }\n",
        "                                  ]\n",
        "                                })\n",
        "                response = client.messages.create(max_tokens = 2024,\n",
        "                                  model = 'claude-3-7-sonnet-20250219',\n",
        "                                  tools = tools,\n",
        "                                  messages = messages)\n",
        "\n",
        "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
        "                    print(response.content[0].text)\n",
        "                    process_query = False"
      ],
      "metadata": {
        "id": "qdVSs9zCz7SU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "znOj8PzV11Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_query(\"HI baby\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8cFw0Ya12f6",
        "outputId": "6d5b90fc-fbdf-40c3-8fba-188563eedf69"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'd be happy to assist you, but I need a bit more information about what you're looking for. If you're interested in searching for academic papers or research on a specific topic, I can help you with that. \n",
            "\n",
            "Would you like to:\n",
            "1. Search for papers on a specific topic on arXiv?\n",
            "2. Look up information about a particular paper if you have its ID?\n",
            "\n",
            "Please let me know what you're interested in, and I'll be glad to help.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Loop"
      ],
      "metadata": {
        "id": "8OrIB6i4gg6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_loop():\n",
        "    print(\"Type your queries or 'quit' to exit.\")\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nQuery: \").strip()\n",
        "            if query.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            process_query(query)\n",
        "            print(\"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError: {str(e)}\")"
      ],
      "metadata": {
        "id": "mnV105Tl14tX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZFimDYogkmC",
        "outputId": "6d9c7d13-e61d-4212-b904-26496221bba7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type your queries or 'quit' to exit.\n",
            "\n",
            "Query: Search for 2 papers on \"LLM interpretability\n",
            "I'll search for papers on LLM interpretability for you. Let me do that right away.\n",
            "Calling tool search_papers with args {'topic': 'LLM interpretability', 'max_results': 2}\n",
            "Results are saved in: papers/llm_interpretability/papers_info.json\n",
            "I found 2 papers on LLM interpretability. Let me retrieve more detailed information about them for you:\n",
            "Calling tool extract_info with args {'paper_id': '2412.07992v3'}\n",
            "Calling tool extract_info with args {'paper_id': '2402.01761v1'}\n",
            "Here are the details of the 2 papers I found on LLM interpretability:\n",
            "\n",
            "### Paper 1: Concept Bottleneck Large Language Models\n",
            "- **Title**: Concept Bottleneck Large Language Models\n",
            "- **Authors**: Chung-En Sun, Tuomas Oikarinen, Berk Ustun, Tsui-Wei Weng\n",
            "- **Published**: December 11, 2024\n",
            "- **Summary**: This paper introduces Concept Bottleneck Large Language Models (CB-LLMs), which build intrinsic interpretability directly into LLMs rather than relying on post-hoc interpretations. The authors demonstrate that CB-LLMs can perform competitively on text classification tasks while providing explicit reasoning. For text generation, the model enables concept detection, controlled generation, and safer outputs. This approach allows users to identify harmful content, control model behavior, and unlearn unwanted concepts, enhancing safety and trustworthiness.\n",
            "- **PDF**: http://arxiv.org/pdf/2412.07992v3\n",
            "\n",
            "### Paper 2: Rethinking Interpretability in the Era of Large Language Models\n",
            "- **Title**: Rethinking Interpretability in the Era of Large Language Models\n",
            "- **Authors**: Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, Jianfeng Gao\n",
            "- **Published**: January 30, 2024\n",
            "- **Summary**: This position paper examines how LLMs are changing interpretable machine learning. The authors note that LLMs can explain complex patterns in natural language, expanding what can be communicated to humans. However, they also highlight challenges like hallucinated explanations and high computational costs. The paper reviews methods for evaluating LLM interpretation and proposes two research priorities: using LLMs to directly analyze new datasets and to generate interactive explanations.\n",
            "- **PDF**: http://arxiv.org/pdf/2402.01761v1\n",
            "\n",
            "Would you like me to search for additional papers on this topic or provide more specific information about these papers?\n",
            "\n",
            "\n",
            "\n",
            "Query: quite\n",
            "I need more information to help you with your request. Could you please provide more details about what you're looking for? For example:\n",
            "\n",
            "- Are you interested in finding research papers on a specific topic?\n",
            "- Are you looking for information about a particular paper?\n",
            "- Do you need help with something else related to academic research?\n",
            "\n",
            "Please provide more context so I can assist you better.\n",
            "\n",
            "\n",
            "\n",
            "Query: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1E-PKQGokADJ"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}